{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "wp = '/home/jose/lung_cancer_ds_bowl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:38:25  INFO     Loading training and test sets\n",
      "04-02 16:38:29  INFO     Training set (1s/total): 31/817\n",
      "04-02 16:38:29  INFO     Test set (1s/total): 79/2128\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:47  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n",
      "04-02 16:38:48  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  32/1280 [..............................] - ETA: 333s - loss: 3.3654 - acc: 0.5312 - fmeasure: 0.4000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:38:55  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  64/1280 [>.............................] - ETA: 222s - loss: 3.2278 - acc: 0.7031 - fmeasure: 0.5333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:38:59  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  96/1280 [=>............................] - ETA: 184s - loss: 3.1320 - acc: 0.7708 - fmeasure: 0.6120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:39:02  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 128/1280 [==>...........................] - ETA: 164s - loss: 3.0704 - acc: 0.8125 - fmeasure: 0.6733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:39:05  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 160/1280 [==>...........................] - ETA: 150s - loss: 3.0254 - acc: 0.8375 - fmeasure: 0.7100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:39:08  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 192/1280 [===>..........................] - ETA: 140s - loss: 2.9919 - acc: 0.8542 - fmeasure: 0.7346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:39:12  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 224/1280 [====>.........................] - ETA: 132s - loss: 2.9659 - acc: 0.8661 - fmeasure: 0.7521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-02 16:39:15  INFO     Final downsampled dataset stats: TP:8, FP:24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plotting\n",
    "from dl_model_pos_patches import  common\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from dl_networks.sample_resnet import ResnetBuilder\n",
    "from dl_utils.tb_callback import TensorBoard\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_model_patches import  common\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from dl_networks.sample_resnet import ResnetBuilder\n",
    "from dl_utils.tb_callback import TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "# PATHS\n",
    "wp = os.environ['LUNG_PATH']\n",
    "\n",
    "\n",
    "INPUT_PATH = '/mnt/hd2/preprocessed5'  # INPUT_PATH = wp + 'data/preprocessed5_sample'\n",
    "VALIDATION_PATH = '/mnt/hd2/preprocessed5_validation_luna'\n",
    "NODULES_PATH = wp + 'data/luna/annotations.csv'\n",
    "#PATCHES_PATH = '/mnt/hd2/patches'  # PATCHES_PATH = wp + 'data/preprocessed5_patches'\n",
    "PATCHES_PATH = '/home/jose/patches_temp'\n",
    "\n",
    "OUTPUT_MODEL = wp + 'models/jm_patches_train_v17.hdf5'  # OUTPUT_MODEL = wp + 'personal/jm_patches_train_v06_local.hdf5'\n",
    "LOGS_PATH = wp + 'logs/%s' % str('v17')\n",
    "\n",
    "\n",
    "\n",
    "## TRAINING -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "def chunks_multichannel(X, y, batch_size=32, augmentation_times=4, thickness=0, is_training=True):\n",
    "    \"\"\"\n",
    "    Batches generator for keras fit_generator. Returns batches of patches 40x40px\n",
    "     - augmentation_times: number of time to return the data augmented\n",
    "     - concurrent_patients: number of patients to load at the same time to add diversity\n",
    "     - thickness: number of slices up and down to add as a channel to the patch\n",
    "    \"\"\"\n",
    "    y = np.expand_dims(y, axis=1)\n",
    "    while 1:\n",
    "        # downsample negatives (reduce 90%)\n",
    "        if is_training:\n",
    "            len1 = int(0.25*batch_size)\n",
    "            idx_1 = [i for i in range(len(y)) if y[i]==1]\n",
    "            idx_1 = random.sample(idx_1, len1)\n",
    "            idx_0 = [i for i in range(len(y)) if y[i]==0]\n",
    "            idx_0 = random.sample(idx_0, batch_size - len1)\n",
    "            selected_samples = idx_0 + idx_1\n",
    "            random.shuffle(selected_samples)\n",
    "        else:\n",
    "            selected_samples = range(len(y))\n",
    "\n",
    "        #selected_samples  = [i for i in range(len(y_orig)) if y_orig[i]==1 or random.randint(0,9)==0]\n",
    "        X = X[selected_samples]\n",
    "        y = y[selected_samples]\n",
    "        logging.info(\"Final downsampled dataset stats: TP:%d, FP:%d\" % (sum(y), len(y)-sum(y)))\n",
    "\n",
    "\n",
    "        a = np.array([X[i][0] for i in range(len(X))])\n",
    "        b = np.array([X[i][1][2:18] for i in range(len(X))])\n",
    "        yield [a,b], y\n",
    "\n",
    "# LOADING PATCHES FROM DISK\n",
    "logging.info(\"Loading training and test sets\")\n",
    "x_train = np.load(os.path.join(PATCHES_PATH, 'x_train_dl_pos_0.npz'))['arr_0']\n",
    "y_train = np.load(os.path.join(PATCHES_PATH, 'y_train_dl_pos_0.npz'))['arr_0']\n",
    "x_test = np.load(os.path.join(PATCHES_PATH, 'x_test_dl_pos_0.npz'))['arr_0']\n",
    "y_test = np.load(os.path.join(PATCHES_PATH, 'y_test_dl_pos_0.npz'))['arr_0']\n",
    "logging.info(\"Training set (1s/total): %d/%d\" % (sum(y_train),len(y_train)))\n",
    "logging.info(\"Test set (1s/total): %d/%d\" % (sum(y_test), len(y_test)))\n",
    "\n",
    "\n",
    "from dl_networks.pos_resnet import posResnet\n",
    "model = posResnet().get_posResnet((3,40,40),(16,18,18))\n",
    "# Load model\n",
    "#model = ResnetBuilder().build_resnet_34((5,40,40),1)\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy','fmeasure'])\n",
    "# logging.info('Loading exiting model...')\n",
    "# model.load_weights(OUTPUT_MODEL)\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "                    generator=chunks_multichannel(x_train, y_train, batch_size=32, thickness=2),\n",
    "                    samples_per_epoch=1280,  # make it small to update TB and CHECKPOINT frequently\n",
    "                    nb_epoch=500,\n",
    "                    verbose=1,\n",
    "                    #class_weight={0:1., 1:4.},\n",
    "                    #callbacks=[tb, model_checkpoint],\n",
    "                    validation_data=chunks_multichannel(x_test, y_test, batch_size=32, thickness=2),  # TODO: is_training=False\n",
    "                    nb_val_samples=32*10,\n",
    "                    max_q_size=64,\n",
    "                    nb_worker=1)  # a locker is needed if increased the number of parallel workers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
